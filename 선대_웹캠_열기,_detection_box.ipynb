{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp4bckR2bdGeQ5xv1Xjk0C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seeun7/face/blob/main/%EC%84%A0%EB%8C%80_%EC%9B%B9%EC%BA%A0_%EC%97%B4%EA%B8%B0%2C_detection_box.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 웹캠 열기\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# 얼굴 인식용 Haar Cascade 로드\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# 가정: 매칭된 얼굴의 인코딩과 이름 리스트\n",
        "# 인코딩 예시는 실사용 시 실제 데이터로 대체해야 함\n",
        "known_face_encodings = [\n",
        "    np.array([0.1, 0.2, 0.3]),  # 예시 인코딩 벡터\n",
        "    np.array([0.4, 0.5, 0.6])\n",
        "]\n",
        "known_face_names = [\n",
        "    \"Person1\",\n",
        "    \"Person2\"\n",
        "]\n",
        "\n",
        "def compare_faces(encoding, known_encodings, threshold=0.5):\n",
        "    # 인코딩 간의 유사성을 계산하는 함수 (유클리디안 거리 사용)\n",
        "    matches = []\n",
        "    for known_encoding in known_encodings:\n",
        "        similarity = np.linalg.norm(encoding - known_encoding)  # 유클리디안 거리 계산\n",
        "        matches.append(similarity <= threshold)  # 유사도가 threshold 이하이면 매칭으로 간주\n",
        "    return matches\n",
        "\n",
        "def get_face_encoding(face_roi):\n",
        "    # 얼굴 인코딩 계산을 위한 가상의 함수\n",
        "    # 실제로는 얼굴 인코딩을 계산하는 로직을 구현해야 함\n",
        "    # 여기는 임의의 인코딩 벡터를 반환하도록 설정\n",
        "    return np.array([0.1, 0.2, 0.3])  # 예시 인코딩 벡터\n",
        "\n",
        "while True:\n",
        "    # 프레임 읽기\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 그레이스케일로 변환\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 얼굴 검출\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # 검출된 각 얼굴에 대해\n",
        "    for (x, y, w, h) in faces:\n",
        "        # 얼굴 부분을 잘라서 인코딩 계산\n",
        "        face_roi = frame[y:y+h, x:x+w]\n",
        "        face_encoding = get_face_encoding(face_roi)  # 얼굴 인코딩 계산\n",
        "\n",
        "        # 얼굴 비교\n",
        "        matches = compare_faces(face_encoding, known_face_encodings)\n",
        "        name = \"저장되지 않은 얼굴입니다.\"\n",
        "\n",
        "        # 매칭된 얼굴이 있는 경우\n",
        "        if True in matches:\n",
        "            first_match_index = matches.index(True)\n",
        "            name = known_face_names[first_match_index]\n",
        "\n",
        "        # 얼굴에 사각형과 이름 표시\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "        cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "    # 결과 화면 표시\n",
        "    cv2.imshow('Face Detection', frame)\n",
        "\n",
        "    # 'q' 키를 누르면 종료\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# 리소스 해제\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "nGoArc4yHgBe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}